
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Thought Cloning</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://www.shengranhu.com/IntelligentGoExplore"/>
    <meta property="og:title" content="Intelligent Go Explore" />
    <meta property="og:description" content="Project page for Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models." />

    


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Intelligent Go-Explore</b>: <br/>Standing on the Shoulders of Giant Foundation Models</br>
                <!-- <strong style="display: inline-block; color: #B22578; font-size: 0.6em; margin-top: 0.5em;">NeurIPS 2023 (Spotlight)</strong> -->
            </h2>
        </div>
        
        <style>
            .author-info {
                text-align: center;
                margin-right: 10px; /* Adjust this to move the block to the right */
            }
            
            .author {
                display: flex;
                justify-content: center;
                gap: 50px; /* Change this value to adjust space between authors */
            }
            
            .author li, .affiliation {
                list-style-type: none; /* This will remove the bullet points */
            }
            
            .affiliation {
                margin-top: 5px; /* Smaller values to reduce space */
                margin-bottom: 5px;
            }
            
            .author-name {
                font-size: 20px; /* Adjust this value to increase or decrease the author name size */
            }
            </style>
            
            <div class="row">
                <div class="col-md-12 text-center">
                    <ul class="author-info">
                        <div class="author">
                            <li>
                                <a href="https://www.conglu.co.uk/" class="author-name">Cong Lu</a><sup>1,2</sup><br/>
                            </li>
                            <li>
                                <a href="https://www.shengranhu.com/" class="author-name">Shengran Hu</a><sup>1,2</sup><br/>
                            </li>
                            <li>
                                <a href="http://jeffclune.com/" class="author-name">Jeff Clune</a><sup>1,2,3</sup><br/>
                            </li>
                        </div>
                        <li class="affiliation">
                            <sup>1</sup>Department of Computer Science, University of British Columbia  
                        </li>
                        <li class="affiliation">
                            <sup>2</sup>Vector Institute  
                        </li>
                        <li class="affiliation">
                            <sup>3</sup>Canada CIFAR AI Chair  
                        </li>
                    </ul>
                </div>
            </div>
              



              <style>
                .link-content {
                  text-align: center;
                }
                
                .list-inline li {
                  margin-right: 50px;  /* Adjust this value to increase/decrease the gap between items */
                  margin-left: 80px;
                }
                
                </style>
                
                <div class="row">
                  <div class="col-md-12 text-center">
                    <ul class="list-inline">
                      <li>
                        <a href="https://arxiv.org/pdf/2405.15143">
                          <div class="link-content">
                            <img src="img/paper_img.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                          </div>
                        </a>
                      </li>
                      <li>
                        <a href="https://github.com/conglu1997/intelligent-go-explore/tree/main">
                          <div class="link-content">
                            <img src="img/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                          </div>
                        </a>
                      </li>
                    </ul>
                  </div>
                </div>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <video width="100%" controls>
                    <source src="data/Thought_Cloning.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video> -->
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    <a href="https://www.nature.com/articles/s41586-020-03157-9">Go-Explore</a> is a powerful family of algorithms designed to solve hard-exploration problems, built on the principle of archiving discovered states, and iteratively returning to and exploring from the most promising states.
                    This approach has led to superhuman performance across a wide variety of challenging problems including Atari games and robotic control, but requires manually designing heuristics to guide exploration (i.e. determine which states to save and explore from, and what actions to consider next), which is time-consuming and infeasible in general.
                    To resolve this, we propose Intelligent Go-Explore (IGE) which greatly extends the scope of the original Go-Explore by replacing these heuristics with the intelligence and internalized human notions of interestingness captured by giant pretrained foundation models (FMs).
                    This provides IGE with a human-like ability to instinctively identify how interesting or promising any new state is (e.g. discovering new objects, locations, or behaviors), even in complex environments where heuristics are hard to define.
                    Moreover, IGE offers the exciting and previously impossible opportunity to <em>recognize and capitalize on serendipitous discoveries that cannot be predicted ahead of time</em>.
                    We evaluate our algorithm on a diverse range of language-based tasks that require search and exploration.
                    In Game of 24, a problem testing multistep mathematical reasoning, IGE reaches 100% success rate 70.8% faster than the best classic graph search baseline.
                    Next, in BabyAI-Text, a challenging partially observable gridworld where an agent has to follow language instructions, IGE exceeds the previous state-of-the-art with orders of magnitude fewer online samples.
                    Finally, in TextWorld, a rich text game, we show the unique ability of IGE to succeed in settings requiring long-horizon exploration where prior state-of-the-art agent FM agents like Reflexion completely fail.
                    Overall, IGE combines the tremendous strengths of FMs and the powerful Go-Explore algorithm, opening up a new frontier of research into creating more generally capable agents with impressive exploration capabilities.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>
                <image src="img/ige_framework.png" class="img-responsive" alt="overview"><br>
                    <p class="text-justify">
                        Intelligent Go-Explore (IGE) integrates the intelligence and internalized human notions of interestingness from giant pretrained FMs into all stages of the <a href="https://www.nature.com/articles/s41586-020-03157-9">Go-Explore</a> algorithm, enabling FM agents to robustly explore in complex environments.
                        <strong>Bottom:</strong> Classic Go-Explore solved hard exploration problems by archiving novel discovered states, resetting to promising ones via domain-specific heuristics, and then performing random exploration.
                        <strong>Top:</strong> Our approach, Intelligent Go-Explore, enables Go-Explore to tackle any problem that is representable in the context of a large language or multimodal model.
                        Instead of manually defining heuristics, we query the foundation model at all stages, enabling our approach to automatically catch and return to serendipitous discoveries, and harness the power of FM agents to explore.
                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Experimental results
                </h3>
                <p class="text-justify">
                    we evaluate Intelligent Go-Explore across three text environments that require search and exploration.
                    We demonstrate IGE's ability to handle partially observable and complex observation spaces, discover solutions involving long chains of actions, and effectively improve the ability of FM agents to explore.
                </p>
                <h4>
                    Game of 24
                </h4>
                <p class="text-justify">
                    We first demonstrate the effectiveness of IGE in a mathematical reasoning task, <a href="https://en.wikipedia.org/wiki/24_(puzzle)">Game of 24</a>.
                    The goal is to perform basic arithmetic operations \( (+, -, \times, \div) \) starting from 4 numbers to obtain 24.
                    For example, given input \( (4, 9, 10, 13) \), a possible solution could be \( (10 - 4) \times (13 - 9) = 24 \).
                </p>
                <img src="img/results_game_of_24.png" class="img-responsive" alt="overview" style="width: 30%; height: auto; display: block; margin: 0 auto;"><br>
                <p class="text-justify">
                    IGE explores the Game of 24 with the intelligence of FMs and reaches 100% success rate on average 70.8% quicker than DFS, the next best baseline.
                    IGE completes all problems within 150 environment operations.
                    Our use of archiving and intelligent action selection allows us to greatly outperform prior LLM agents with an equal number of operations performed.
                    The success rate is computed over 100 test problems.
                </p>
                
                <h4>
                    BabyAI-Text
                </h4>
                <p class="text-justify">
                    Next, we show that IGE scales to the <a href="https://github.com/flowersteam/Grounding_LLMs_with_online_RL">BabyAI-Text</a> environment, which is a procedurally-generated partially-observable 2D gridworld with text-based observations.
                    The agent is given a textual goal instruction which could correspond to one or more instructions in a sequence, e.g. "pick up X and then go to Y".
                    The task is challenging even for humans to complete and requires forming a model of the world from partial text descriptions.
                    This kind of state observation would make it <em>hard to define heuristics to determine how good any particular state is</em>, as in classic Go-Explore.
                    The optimal path to a solution may include moving blocking objects as well as finding keys to open doors.
                </p>
                <image src="img/results_baby_ai.png" class="img-responsive" alt="overview"><br>  
                <p class="text-justify">
                    IGE can find solutions to challenging tasks in the BabyAI-Text environment more effectively and with orders of magnitude fewer online steps than prior RL-trained baselines <a href="https://arxiv.org/abs/2302.02662">GLAM</a>.
                    Task types are in order of difficulty.
                    As tasks become more difficult, the performance gap of IGE v.s. the LLM baselines grows.
                    We show the mean and 95% bootstrap confidence interval over 25 seeds per environment type.
                </p>

                <h4>
                    TextWorld
                </h4>
                <p class="text-justify">
                    Finally, we show IGE's ability to tackle tasks requiring long-horizon memory and planning, exploration, and commonsense in <a href="https://github.com/microsoft/TextWorld">TextWorld</a>, a classic text-based agent benchmark.
                    We consider three challenging games in Textworld: Treasure Hunter, The Cooking Game, and Coin Collector.
                    In each game, the agent needs to complete the task while navigating a maze of different rooms, while only seeing the current room's description in text. 
                    The agent interacts with the world using free-form natural language commands, such as "go east" or "cook potato with oven".
                    In Treasure Hunter, the agent has to find a specific item by exploring, finding keys, and unlocking doors and containers.
                    In The Cooking Game, the agent must find a recipe, locate and process (e.g., dice, cut, chop) ingredients, and cook them according to the recipe using various kitchen appliances (e.g., oven, pan).
                    In Coin Collector, the agent must find a coin randomly located in the maze, testing its navigation and exploration skills.
                </p>
                <image src="img/results_textworld.png" class="img-responsive" alt="overview"><br>  
                <p class="text-justify">
                    IGE outperforms state-of-the-art FM agents in three challenging text games in TextWorld. 
                    These results illustrate the powerful capabilities of planning, commonsense reasoning, and exploration of IGE.
                    Notably, in the Coin Collector game where hard exploration is required, we observe BFS-like search behavior emerge in IGE, enabling it to find the most efficient solution where all other approaches exhaust the environment horizon.
                    We show the mean and 95% bootstrap confidence interval over 25 seeds for each game.
                </p>

            </div>
        </div>
        
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{lu2024IntelligentGoExplore,
title={{Intelligent Go-Explore}: Standing on the Shoulders of Giant Foundation Models},
author={Lu, Cong, and Hu, Shengran and Clune, Jeff},
journal={arXiv preprint arXiv:2405.15143},
year={2024}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    This work was supported by the Vector Institute, the Canada CIFAR AI Chairs program, grants from Schmidt Futures and Open Philanthropy, an NSERC Discovery Grant, and a generous donation from Rafael Cosman.
                    We thank Aaron Dharna, Ben Norman, and Jenny Zhang from our lab at the University of British Columbia for insightful discussions for insightful discussions and/or feedback on early drafts of this work.
                <br>
                
                <br/>The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
